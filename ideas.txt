(попробовал) 1. Увеличить размер батча + увеличить начальный lr = 0.1 * (b=32)/256
(попробовал) 2. Добавить mixup/cutout
3. начинать почти с нулевой скорости обучения, но быстро поднять ее до той, которую хотели в начале(warmup)
(попробовал) 4. cosine decay lr
(попробовал) 5. label smoothing
(попробовал) 6. кроссэнтропия сбалансированная по классам
7. metric-learning/self-supervised learning
8. randomaffine, randomperspevtive, 

хочу с помощью ssl предобучить веса модели, прежде чем делать sl